{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "import pickle\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chunk = pd.read_csv('train.csv', chunksize = 500000, low_memory = False)\n",
    "chunks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid = [0]*500000\n",
    "coord_list = ['pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude', 'fare_amount']\n",
    "def mark_invalid(chunk):\n",
    "    for c in coord_list:\n",
    "        for i in chunk.index:\n",
    "            if(c == \"pickup_longitude\" or c == \"dropoff_longitude\"):\n",
    "                if(chunk[c][i].astype(float) > -73.699215 or chunk[c][i].astype(float) < -74.257159):\n",
    "#                     chunk = chunk.replace(chunk[c][i],np.nan)\n",
    "#                     chunk = chunk.drop([i])\n",
    "                    invalid[i%500000] = 1\n",
    "            elif (c == \"pickup_latitude\" or c == \"dropoff_latitude\"):\n",
    "                if(chunk[c][i].astype(float) > 40.915568 or chunk[c][i].astype(float) < 40.495992):\n",
    "#                     chunk = chunk.replace(chunk[c][i],np.nan)\n",
    "#                     chunk = chunk.drop([i])\n",
    "                    invalid[i%500000] = 1\n",
    "            elif(c == \"fare_amount\"):\n",
    "                if(chunk[c][i] >= 200 or chunk[c][i] <= 0):\n",
    "#                     chunk = chunk.drop([i])\n",
    "                    invalid[i%500000] = 1\n",
    "    return chunk\n",
    "\n",
    "invalid_test = [0]*1000000\n",
    "coord_list_test = ['pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude']\n",
    "def mark_invalid_test(chunk):\n",
    "    for c in coord_list_test:\n",
    "        for i in chunk.index:\n",
    "            if(c == \"pickup_longitude\" or c == \"dropoff_longitude\"):\n",
    "                if(chunk[c][i].astype(float) > -73.699215 or chunk[c][i].astype(float) < -74.257159):\n",
    "#                     chunk = chunk.replace(chunk[c][i],np.nan)\n",
    "#                     chunk = chunk.drop([i])\n",
    "                    invalid_test[i%1000000] = 1\n",
    "            elif (c == \"pickup_latitude\" or c == \"dropoff_latitude\"):\n",
    "                if(chunk[c][i].astype(float) > 40.915568 or chunk[c][i].astype(float) < 40.495992):\n",
    "#                     chunk = chunk.replace(chunk[c][i],np.nan)\n",
    "#                     chunk = chunk.drop([i])\n",
    "                    invalid_test[i%1000000] = 1\n",
    "    return chunk\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark_outlier(chunk, data_1):\n",
    "    outliers_indices=[]\n",
    "    threshold = 3\n",
    "    mean_1 = np.mean(data_1)\n",
    "    std_1 = np.std(data_1)\n",
    "    \n",
    "#     length = len(data_1)\n",
    "    for i in chunk.index:\n",
    "        z_score= (data_1[i] - mean_1)/std_1 \n",
    "        if np.abs(z_score) > threshold:\n",
    "            outliers_indices.append(i)\n",
    "    for i in outliers_indices:\n",
    "#         chunk = chunk.drop([i])\n",
    "        chunk['invalid'][i] = 1\n",
    "    return chunk\n",
    "\n",
    "\n",
    "# print(len(detect_outlier(chunks[1]['fare_amount'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_datetime(chunk):\n",
    "    hours = []\n",
    "    mins = []\n",
    "    secs = []\n",
    "    years = []\n",
    "    months = []\n",
    "    days = []\n",
    "    length = len(chunk['pickup_longitude'])\n",
    "    \n",
    "    for i in chunk.index:\n",
    "        years.append(int(chunk['pickup_datetime'][i][0:4]))\n",
    "        months.append(int(chunk['pickup_datetime'][i][5:7]) - 1) # 1 is subtracted to aid in days from jan 1st calculations\n",
    "        days.append(int(chunk['pickup_datetime'][i][8:10]))\n",
    "        hours.append(int(chunk['pickup_datetime'][i][11:13]))\n",
    "        mins.append(int(chunk['pickup_datetime'][i][14:16]))\n",
    "        secs.append(int(chunk['pickup_datetime'][i][17:19]))\n",
    "\n",
    "    chunk['years'] = years\n",
    "    chunk['months'] = months\n",
    "    chunk['days'] = days\n",
    "    chunk['hours'] = hours\n",
    "    chunk['mins'] = mins\n",
    "    chunk['secs'] = secs\n",
    "    \n",
    "    return chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_datetime(chunk):\n",
    "    chunk['secs_past_midnight'] = (chunk['hours']*3600) + (chunk['mins']*60) + (chunk['secs'])\n",
    "    chunk['sin_spm'] = np.sin(2*np.pi*(chunk['secs_past_midnight']/86400))\n",
    "    chunk['cos_spm'] = np.cos(2*np.pi*(chunk['secs_past_midnight']/86400))\n",
    "    chunk['days_past_jan1'] = (chunk['months']*30) + (chunk['days'])\n",
    "    chunk['sin_dpj'] = np.sin(2*np.pi*(chunk['days_past_jan1']/365))\n",
    "    chunk['cos_dpj'] = np.cos(2*np.pi*(chunk['days_past_jan1']/365))\n",
    "    \n",
    "    return chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(chunk):\n",
    "    y = chunk['fare_amount']\n",
    "    X = pd.DataFrame(chunk)\n",
    "    X = X.drop(['fare_amount','key','pickup_datetime', 'years', 'months', 'days', 'hours', 'mins', 'secs', 'secs_past_midnight', 'days_past_jan1'], axis = 1)\n",
    "#     X = StandardScaler().fit_transform(X)\n",
    "    return (X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model_rmse(X, y, linreg = LinearRegression()):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "#     linreg = LinearRegression()\n",
    "    linreg.fit(X_train, y_train)\n",
    "    y_pred = linreg.predict(X_test)\n",
    "    rmse = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "    return (linreg, rmse)\n",
    "\n",
    "# X1_train, X1_test, y1_train, y1_test = train_test_split(features, target, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, filename): \n",
    "#     filename = 'model.sav'\n",
    "    pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(filename): \n",
    "    model = pickle.load(open(filename, 'rb'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def req_columns_test(chunk):\n",
    "    temp = pd.DataFrame(chunk)\n",
    "    temp = temp.drop(['key','pickup_datetime', 'years', 'months', 'days', 'hours', 'mins', 'secs', 'secs_past_midnight', 'days_past_jan1'], axis = 1)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading chunks and applying functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brahma/.local/lib/python3.6/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         pickup_longitude  pickup_latitude  dropoff_longitude  \\\n",
      "1000000        -73.976162        40.750897         -73.955782   \n",
      "1000001        -73.975890        40.760322         -73.946460   \n",
      "1000002        -73.972932        40.764252         -74.000461   \n",
      "1000003        -73.984860        40.742647         -73.993935   \n",
      "1000004        -73.955225        40.820190         -73.953910   \n",
      "\n",
      "         dropoff_latitude  passenger_count  invalid   sin_spm   cos_spm  \\\n",
      "1000000         40.775450                1        0 -0.938191  0.346117   \n",
      "1000001         40.780463                1        0 -0.874831  0.484428   \n",
      "1000002         40.742588                2        0  0.557805  0.829972   \n",
      "1000003         40.745870                1        0 -0.818776 -0.574112   \n",
      "1000004         40.816990                1        0  0.857167 -0.515038   \n",
      "\n",
      "          sin_dpj   cos_dpj  manhattan_dist  \n",
      "1000000  0.993257 -0.115935        0.044933  \n",
      "1000001  0.680773 -0.732494        0.049571  \n",
      "1000002 -0.891981  0.452072        0.049193  \n",
      "1000003 -0.230306 -0.973118        0.012298  \n",
      "1000004  0.880012 -0.474951        0.004515  \n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for chunk in df_chunk:\n",
    "    chunk = pd.DataFrame(chunk)\n",
    "    if (count == 0):\n",
    "        model = LinearRegression()\n",
    "    else:\n",
    "        model = load_model(\"model.sav\")\n",
    "        \n",
    "    chunk = mark_invalid(chunk)\n",
    "    chunk['invalid'] = invalid\n",
    "    chunk.dropna(inplace = True)\n",
    "    chunk = split_datetime(chunk)\n",
    "    chunk = modify_datetime(chunk)\n",
    "    chunk = mark_outlier(chunk, chunk['fare_amount'])\n",
    "    chunk['manhattan_dist'] = abs(chunk['pickup_latitude']-chunk['dropoff_latitude']) + abs(chunk['pickup_longitude']-chunk['dropoff_longitude'])\n",
    "    (X1, y1) = split_data(chunk)\n",
    "    X1 = pd.DataFrame(X1)\n",
    "    print(X1.head())\n",
    "    break\n",
    "    model, rmse = fit_model_rmse(X1, y1, model)\n",
    "    save_model(model, \"model.sav\")\n",
    "    print(rmse)\n",
    "    \n",
    "    if (count == 0):\n",
    "        chunks.append(pd.DataFrame(chunk))\n",
    "    count += 1\n",
    "    if(count == 2):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "test_chunk = pd.read_csv('test.csv', chunksize = 1000000, low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000, 20)\n",
      "(1000000, 10)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (1000000,10) and (11,) not aligned: 10 (dim 1) != 11 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-26791365093d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mreq_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq_columns_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'key'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mfinal_dfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \"\"\"\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0m_preprocess_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36m_decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'coo'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         return safe_sparse_dot(X, self.coef_.T,\n\u001b[0;32m--> 206\u001b[0;31m                                dense_output=True) + self.intercept_\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (1000000,10) and (11,) not aligned: 10 (dim 1) != 11 (dim 0)"
     ]
    }
   ],
   "source": [
    "\n",
    "# print(pd.DataFrame(test_chunk).shape)\n",
    "test_chunks = []\n",
    "final_dfs = []\n",
    "for chunk in test_chunk:\n",
    "    chunk = pd.DataFrame(chunk)\n",
    "    if(count == 0):\n",
    "        model = load_model(\"model.sav\")\n",
    "    chunk = mark_invalid_test(chunk)\n",
    "    chunk['invalid'] = invalid_test\n",
    "    chunk = split_datetime(chunk)\n",
    "    chunk = modify_datetime(chunk)\n",
    "    if(count == 0):\n",
    "        test_chunks.append(pd.DataFrame(chunk))\n",
    "    print(chunk.shape)\n",
    "    req_df = req_columns_test(chunk)\n",
    "    print(req_df.shape)\n",
    "    y_pred = model.predict(req_df)\n",
    "    df = pd.concat([chunk['key'], y_pred], axis = 1)\n",
    "    final_dfs.append(df)\n",
    "    \n",
    "    count += 1\n",
    "    break\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>invalid</th>\n",
       "      <th>years</th>\n",
       "      <th>months</th>\n",
       "      <th>days</th>\n",
       "      <th>hours</th>\n",
       "      <th>mins</th>\n",
       "      <th>secs</th>\n",
       "      <th>secs_past_midnight</th>\n",
       "      <th>sin_spm</th>\n",
       "      <th>cos_spm</th>\n",
       "      <th>days_past_jan1</th>\n",
       "      <th>sin_dpj</th>\n",
       "      <th>cos_dpj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-01 00:01:04.0000003</td>\n",
       "      <td>2009-01-01 00:01:04 UTC</td>\n",
       "      <td>-73.972484</td>\n",
       "      <td>40.742743</td>\n",
       "      <td>-73.918937</td>\n",
       "      <td>40.764496</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>0.004654</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>1</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.999852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-01-01 00:01:26.0000001</td>\n",
       "      <td>2009-01-01 00:01:26 UTC</td>\n",
       "      <td>-73.985850</td>\n",
       "      <td>40.722826</td>\n",
       "      <td>-73.986301</td>\n",
       "      <td>40.739347</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>86</td>\n",
       "      <td>0.006254</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>1</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.999852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-01-01 00:04:42.0000001</td>\n",
       "      <td>2009-01-01 00:04:42 UTC</td>\n",
       "      <td>-73.988917</td>\n",
       "      <td>40.740142</td>\n",
       "      <td>-73.982769</td>\n",
       "      <td>40.777291</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>282</td>\n",
       "      <td>0.020506</td>\n",
       "      <td>0.999790</td>\n",
       "      <td>1</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.999852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-01-01 00:04:54.0000001</td>\n",
       "      <td>2009-01-01 00:04:54 UTC</td>\n",
       "      <td>-73.977163</td>\n",
       "      <td>40.764490</td>\n",
       "      <td>-73.914474</td>\n",
       "      <td>40.771575</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>54</td>\n",
       "      <td>294</td>\n",
       "      <td>0.021379</td>\n",
       "      <td>0.999771</td>\n",
       "      <td>1</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.999852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-01-01 00:04:59.0000004</td>\n",
       "      <td>2009-01-01 00:04:59 UTC</td>\n",
       "      <td>-73.948849</td>\n",
       "      <td>40.778003</td>\n",
       "      <td>-73.977678</td>\n",
       "      <td>40.748692</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>59</td>\n",
       "      <td>299</td>\n",
       "      <td>0.021742</td>\n",
       "      <td>0.999764</td>\n",
       "      <td>1</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.999852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           key          pickup_datetime  pickup_longitude  \\\n",
       "0  2009-01-01 00:01:04.0000003  2009-01-01 00:01:04 UTC        -73.972484   \n",
       "1  2009-01-01 00:01:26.0000001  2009-01-01 00:01:26 UTC        -73.985850   \n",
       "2  2009-01-01 00:04:42.0000001  2009-01-01 00:04:42 UTC        -73.988917   \n",
       "3  2009-01-01 00:04:54.0000001  2009-01-01 00:04:54 UTC        -73.977163   \n",
       "4  2009-01-01 00:04:59.0000004  2009-01-01 00:04:59 UTC        -73.948849   \n",
       "\n",
       "   pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \\\n",
       "0        40.742743         -73.918937         40.764496                1   \n",
       "1        40.722826         -73.986301         40.739347                1   \n",
       "2        40.740142         -73.982769         40.777291                1   \n",
       "3        40.764490         -73.914474         40.771575                1   \n",
       "4        40.778003         -73.977678         40.748692                2   \n",
       "\n",
       "   invalid  years  months  days  hours  mins  secs  secs_past_midnight  \\\n",
       "0        0   2009       0     1      0     1     4                  64   \n",
       "1        0   2009       0     1      0     1    26                  86   \n",
       "2        0   2009       0     1      0     4    42                 282   \n",
       "3        0   2009       0     1      0     4    54                 294   \n",
       "4        0   2009       0     1      0     4    59                 299   \n",
       "\n",
       "    sin_spm   cos_spm  days_past_jan1   sin_dpj   cos_dpj  \n",
       "0  0.004654  0.999989               1  0.017213  0.999852  \n",
       "1  0.006254  0.999980               1  0.017213  0.999852  \n",
       "2  0.020506  0.999790               1  0.017213  0.999852  \n",
       "3  0.021379  0.999771               1  0.017213  0.999852  \n",
       "4  0.021742  0.999764               1  0.017213  0.999852  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_chunks[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_chunks[0].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_chunks[0].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization plots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "print(chunks[0][\"pickup_longitude\"].plot.hist(ax = ax, title=\"pickup longitude\",bottom=1, bins=25))\n",
    "ax.set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "print(chunks[0][\"pickup_latitude\"].plot.hist(ax = ax, title=\"pickup latitude\",bottom=1, bins=25))\n",
    "ax.set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "print(chunks[0][\"dropoff_longitude\"].plot.hist(ax = ax, title=\"dropoff longitude\",bottom=1, bins=25))\n",
    "ax.set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "print(chunks[0][\"dropoff_latitude\"].plot.hist(ax = ax, title=\"dropoff latitude\",bottom=1, bins=25))\n",
    "ax.set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "print(chunks[0][\"passenger_count\"].plot.hist(ax = ax, title=\"passenger count\",bottom=1, bins=25))\n",
    "ax.set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, sharex = True, sharey = True)\n",
    "ax1.scatter(chunks[0][\"pickup_latitude\"],chunks[0][\"fare_amount\"])\n",
    "# ax1.xlabel(\"pickup_latitude\")\n",
    "# ax1.ylabel(\"fare_amount\")\n",
    "ax2.scatter(chunks[0][\"pickup_longitude\"],chunks[0][\"fare_amount\"])\n",
    "# ax2.xlabel(\"pickup_longitude\")\n",
    "# ax2.ylabel(\"fare_amount\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(chunks[0][\"dropoff_latitude\"],chunks[0][\"fare_amount\"])\n",
    "plt.xlabel(\"dropoff_latitude\")\n",
    "plt.ylabel(\"fare_amount\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(chunks[0][\"dropoff_longitude\"],chunks[0][\"fare_amount\"])\n",
    "plt.xlabel(\"dropoff_longitude\")\n",
    "plt.ylabel(\"fare_amount\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(chunks[0][\"passenger_count\"],chunks[0][\"fare_amount\"])\n",
    "plt.xlabel(\"passenger_count\")\n",
    "plt.ylabel(\"fare_amount\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(chunks[0].fare_amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks[0].to_csv('preprocessed.csv')\n",
    "chunk1 = pd.read_csv('preprocessed.csv')\n",
    "chunks.append(chunk1)\n",
    "chunks[1].head()\n",
    "chunks[0].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices = detect_outlier(chunks[1]['fare_amount'])\n",
    "# for i in indices:\n",
    "#     chunks[1] = chunks[1].drop([i])\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks[1].to_csv('preprocessed1.csv')\n",
    "chunks.append(pd.read_csv('preprocessed1.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restricting coordinates to NYC\n",
    "\n",
    "All coordinates outside NYC are directly dropped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing all rows with null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(chunks[0])\n",
    "# print(chunks[0].isnull().sum())\n",
    "# chunks[0].dropna(inplace = True)\n",
    "# print(chunks[0].isnull().sum())\n",
    "# chunks[0]['pickup_datetime'][0]\n",
    "# chunks[0].describe()\n",
    "# type(chunks[0]['dropoff_longitude'][161652])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting pickup date time "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating secs after midnight and days past jan 1st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunks[0] = chunks[0].drop(['Unnamed: 0', 'Unnamed: 0.1'], axis = 1)\n",
    "chunks[1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunks[0]['manhattan_dist'] = abs(chunks[0]['pickup_latitude']-chunks[0]['dropoff_latitude']) + abs(chunks[0]['pickup_longitude']-chunks[0]['dropoff_longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = chunks[0].drop(['fare_amount','key','pickup_datetime', 'years', 'months', 'days', 'hours', 'mins', 'secs', 'secs_past_midnight', 'days_past_jan1'], axis = 1)\n",
    "# target = chunks[0]['fare_amount']\n",
    "# features = StandardScaler().fit_transform(features)\n",
    "\n",
    "# pca = PCA(n_components=6)\n",
    "# principalComponents = pca.fit_transform(features)\n",
    "# principalDf = pd.DataFrame(data = principalComponents, columns = ['PrincipalC1', 'PrincipalC2', 'PrincipalC3','PrincipalC4', 'PrincipalC5', 'PrincipalC6'])\n",
    "# finalDf = pd.concat([principalDf, target], axis=1)\n",
    "# finalDf.head()\n",
    "# chunks[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating X and y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test train split & Linear Regression & RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "# print(X1_train.shape)\n",
    "# print(y1_train.shape)\n",
    "# print(X1_test.shape)\n",
    "# print(y1_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linreg1 = LinearRegression()\n",
    "# linreg1.fit(X1_train, y1_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = linreg.predict(X_test)\n",
    "# y1_pred = linreg1.predict(X1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Without PCA: \", np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "# print(\"With PCA: \", np.sqrt(metrics.mean_squared_error(y1_test, y1_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
